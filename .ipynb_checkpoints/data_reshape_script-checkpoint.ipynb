{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Money Diaries Data Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.932536Z",
     "start_time": "2018-07-04T14:34:58.074587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.939281Z",
     "start_time": "2018-07-04T14:34:58.934958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('max_rows', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.948424Z",
     "start_time": "2018-07-04T14:34:58.943754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dollar_pattern = r\"\\$\\d+,?\\d*(?:\\.\\d+)?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Wide `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.960015Z",
     "start_time": "2018-07-04T14:34:58.951869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_total(s):\n",
    "    total = re.findall(dollar_pattern, s)[-1]\n",
    "    total = ''.join(total.split(','))\n",
    "    return float(total.strip('$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.971269Z",
     "start_time": "2018-07-04T14:34:58.963279Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_salary(s):\n",
    "    try:\n",
    "        salary = re.findall(dollar_pattern, s)[0]\n",
    "        salary = ''.join(salary.split(','))\n",
    "        return float(salary.strip('$'))\n",
    "    except IndexError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.988309Z",
     "start_time": "2018-07-04T14:34:58.975686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_totals_cols(df):\n",
    "    for day in df.columns[:-2]:\n",
    "        new_col = day + '_total'\n",
    "        df[new_col] = df[day].apply(parse_total)\n",
    "    \n",
    "    totals = [c for c in df.columns if '_total' in c]\n",
    "    df['weekly_total'] = df[totals].sum(axis=1)\n",
    "    \n",
    "    df['salary'] = df['title'].apply(parse_salary)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:58.999878Z",
     "start_time": "2018-07-04T14:34:58.991971Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cutoff_at_daily_total(s):\n",
    "    # Found this regex pattern by carefully inspecting the text.\n",
    "    # daily_total_pattern = \"Total: \" + dollar_pattern\n",
    "    daily_total_pattern = \"T[cha]*otal[ amount ]*[ sSpent]*: \" + dollar_pattern\n",
    "    day_seven_total = re.search(daily_total_pattern, s).group(0)\n",
    "    cleaned = re.split(daily_total_pattern, s)[0].rstrip() + \" \" + day_seven_total\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.011994Z",
     "start_time": "2018-07-04T14:34:59.002738Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_location(s):\n",
    "    trim_right = s.split(\"In \")[-1]\n",
    "    trim_left = trim_right.split('On')[0]\n",
    "    location = trim_left.strip().strip(',')\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.024183Z",
     "start_time": "2018-07-04T14:34:59.015632Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_location(df):\n",
    "    df['location'] = df.title.apply(lambda x: parse_location(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.036866Z",
     "start_time": "2018-07-04T14:34:59.029468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_trailing_text(df):\n",
    "    df['day_seven'] = df.day_seven.apply(lambda x: cutoff_at_daily_total(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.137005Z",
     "start_time": "2018-07-04T14:34:59.040688Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hacky_replaces(s):\n",
    "    '''\n",
    "    There must be a better way...\n",
    "    '''\n",
    "    split = s.split('|')\n",
    "    if ':' not in split[0]:\n",
    "        split.pop(0)\n",
    "        s = '|'.join(split)\n",
    "    s = s.replace('||', '')\n",
    "    s = s.replace('Monthly Expenses|', '')\n",
    "    s = s.replace('Monthly expenses|', '')\n",
    "    s = s.replace('Monthly Expenses:|', '')\n",
    "    s = s.replace('Additional Expenses|', '')\n",
    "    s = s.replace('Additional Expenses:|', '')\n",
    "    s = s.replace('Annual Expenses|', '')\n",
    "    s = s.replace('Yearly Expenses:|', '')\n",
    "    s = s.replace('Yearly Expenses|', '')\n",
    "    s = s.replace('Monthly Subscriptions/ Donations|', '')\n",
    "    s = s.replace('S|', '')\n",
    "    s = s.replace('hip:|$40Sub', 'hip:|$40|Sub')\n",
    "    s = s.replace('ty:|$40Sub', 'ty:|$40|Sub')\n",
    "    s = s.replace('Digit|', '')\n",
    "    s = s.replace('Your Spending In Your State:|', '')\n",
    "    s = s.replace('here|', '')\n",
    "    s = s.replace('This week:|', '')\n",
    "    s = s.replace('Shared My boyfriend and I have a joint account and each contribute $500/month to cover the following expenses (plus groceries, gas, and pet supplies):|', '')\n",
    "    s = s.replace('Every month I withdraw $600 and divide it into physical envelopes for various expenses, including food ($200) and the following:|', '')\n",
    "    s = s.replace('This week: A biomedical research analyst who makes $56,000 per year and spends it on bike accessories and a sleeping bag.|', '')\n",
    "    s = s.replace('our guide to managing your money every day|', '')\n",
    "    s = s.replace('All Other I put all expenses (below) on my credit card, which I pay in full every month. I have no credit card debt.|', '')\n",
    "    s = s.replace('Monthly Revenue In Addition to Salary:|', '')\n",
    "    s = s.replace('Monthly Loan Payments|Student Loans:|', 'Student Loans:|')\n",
    "    s = s.replace('Loan Payments|Students Loans:|', 'Student Loans:|')\n",
    "    s = s.replace('Split Expenses With My Boyfriend From Our Joint account|', '')\n",
    "    s = s.replace('All Other Expenses|', '')\n",
    "    s = s.replace(', for the inspiration.)|', '')\n",
    "    s = s.replace(\"Editor's Note:|\", '')\n",
    "    s = s.replace('Hamilton|', '')\n",
    "    s = s.replace('fe|si', 'fe si')\n",
    "    s = s.replace('ly|th', 'ly th')\n",
    "    s = s.replace('he|Su', 'he Su')\n",
    "    s = s.replace('al.Sa', 'al|Sa')\n",
    "    s = s.replace('ly|Ma', 'ly Ma')\n",
    "    s = s.replace('ok.|My', 'ok. My')\n",
    "    s = s.replace('is|good.', 'is good.')\n",
    "    s = s.replace('ngs|get', 'ngs get')\n",
    "    s = s.replace('Mortgage:$1,517', 'Mortgage:|$1,517')\n",
    "    s = s.replace('fresh piecesOccupation:|', 'Occupation:|')\n",
    "    s = s.replace('|:|', ':|')\n",
    "    s = s.replace('taxes|,|etc.|', 'taxes, etc.')\n",
    "    s = s.replace('All Other Utility bill: $40; Electricity bill: $40; Internet: $44; Car payment: $354; Car insurance: $93; Spotify: $10', 'All Other Utility bill:|$40|Electricity bill:|$40|Internet:|$44|Car payment:|$354|Car insurance:|$93|Spotify:|$10')\n",
    "    s = s.replace('All Other Netflix: $10.73', 'Netflix:|$10.73')\n",
    "    s = s.replace('through 401(k):|I contribute', 'through 401(k): I contribute')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.147182Z",
     "start_time": "2018-07-04T14:34:59.140503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_hacky_replaces(df):\n",
    "    df['intro'] = df.intro.apply(lambda x: hacky_replaces(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.325779Z",
     "start_time": "2018-07-04T14:34:59.151217Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'diaries.json'\n",
    "wide_df = pd.read_json(filename)\n",
    "wide_df = add_totals_cols(wide_df)\n",
    "wide_df = add_location(wide_df)\n",
    "wide_df = clean_trailing_text(wide_df)\n",
    "wide_df = do_hacky_replaces(wide_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide `DataFrame` with cleaned, unshaped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build skinny `DataFrame` of Monthly Expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:34:59.339857Z",
     "start_time": "2018-07-04T14:34:59.328252Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_expenses(txt):\n",
    "    '''\n",
    "    Return a small DataFrame of the monthly expenses listed for one diary.\n",
    "    '''\n",
    "    d = {}\n",
    "    for i in range(0, len(txt.split('|')), 2):\n",
    "        k = txt.split('|')[i].rstrip(':')\n",
    "        v = txt.split('|')[i+1]\n",
    "        d[k] = v\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df = df.reset_index()\n",
    "    df = df.rename_axis({'index': 'title', 0: 'value'},axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:00.075271Z",
     "start_time": "2018-07-04T14:34:59.342891Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for row_ix in range(wide_df.shape[0]):\n",
    "    small_expenses_df = row_to_expenses(wide_df.loc[row_ix, 'intro'])\n",
    "    small_expenses_df['diary_index'] = row_ix\n",
    "    dfs.append(small_expenses_df)\n",
    "monthly_expense_df = pd.concat(dfs, axis=0)\n",
    "monthly_expense_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:00.097081Z",
     "start_time": "2018-07-04T14:35:00.077555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>value</th>\n",
       "      <th>diary_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>Digital Marketing Account Manager</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Industry</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Location</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salary</td>\n",
       "      <td>$37,100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title                              value  diary_index\n",
       "0  Occupation  Digital Marketing Account Manager            0\n",
       "1    Industry                        Hospitality            0\n",
       "2         Age                                 26            0\n",
       "3    Location                    Dublin, Ireland            0\n",
       "4      Salary                            $37,100            0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_expense_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skinny `DataFrame` with each row representing a diarist's single monthly expense.\n",
    "\n",
    "Mostly works but there is still some cleanup needed.  Might need to point-and-shoot e.g. in Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build skinny `DataFrame` of Daily Expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:00.110462Z",
     "start_time": "2018-07-04T14:35:00.099948Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_cols = ['day_one_total', 'day_two_total',\n",
    "             'day_three_total', 'day_four_total',\n",
    "             'day_five_total', 'day_six_total',\n",
    "             'day_seven_total']\n",
    "\n",
    "day_totals = wide_df[day_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:00.124993Z",
     "start_time": "2018-07-04T14:35:00.113893Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_day_totals(row_ix, day_totals):\n",
    "    amounts = day_totals.loc[row_ix,:].values\n",
    "    amounts = pd.DataFrame(amounts, columns=['day_total'])\n",
    "    amounts['day_nm'] = np.arange(1,8)\n",
    "    amounts['diary_index'] = row_ix\n",
    "    return amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:00.682314Z",
     "start_time": "2018-07-04T14:35:00.128881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for row_ix in range(wide_df.shape[0]):\n",
    "    df = row_to_day_totals(row_ix, day_totals)\n",
    "    dfs.append(df)\n",
    "daily_expense_df = pd.concat(dfs, axis=0)\n",
    "daily_expense_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skinny `DataFrame` with rows representing total daily expense in a diary-day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build skinny `DataFrame` of diarists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:18.313627Z",
     "start_time": "2018-07-04T14:35:18.303322Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diarist_df = wide_df[['salary', 'location', 'url']]\n",
    "diarist_df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skinny `DataFrame` with each row representing a diarist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build skinny `DataFrame` of day text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:20.483356Z",
     "start_time": "2018-07-04T14:35:20.476649Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_text_cols = ['day_one', 'day_two',\n",
    "             'day_three', 'day_four',\n",
    "             'day_five', 'day_six',\n",
    "             'day_seven']\n",
    "\n",
    "day_text = wide_df[day_text_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:20.547451Z",
     "start_time": "2018-07-04T14:35:20.541584Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_day_text(row_ix, day_text):\n",
    "    txt = day_text.loc[0,:].values\n",
    "    txt = pd.DataFrame(txt, columns=['day_rawtext'])\n",
    "    txt['day_nm'] = np.arange(1,8)\n",
    "    txt['diary_index'] = row_ix\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:21.272566Z",
     "start_time": "2018-07-04T14:35:20.671274Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for row_ix in range(wide_df.shape[0]):\n",
    "    df = row_to_day_text(row_ix, day_text)\n",
    "    dfs.append(df)\n",
    "daily_text_df = pd.concat(dfs, axis=0)\n",
    "daily_text_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skinny `DataFrame` holding raw text data.  Each row is a diary-day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to disk for manual cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:21.280637Z",
     "start_time": "2018-07-04T14:35:21.275696Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'monthly_expenses.csv': monthly_expense_df,\n",
    "    'daily_expenses.csv': daily_expense_df,\n",
    "    'diarists.csv': diarist_df,\n",
    "    'daily_text.csv': daily_text_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:35:21.517653Z",
     "start_time": "2018-07-04T14:35:21.284470Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = os.path.dirname(os.path.abspath(__name__))\n",
    "if not os.path.exists(os.path.join(directory, 'data_reshape')):\n",
    "    os.mkdir(os.path.join(directory, 'data_reshape'))\n",
    "for basename, df in dataframes.items():\n",
    "    savepath = os.path.join(directory, 'data_reshape', basename)\n",
    "#     df.to_csv(savepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the line above to enable the save."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
